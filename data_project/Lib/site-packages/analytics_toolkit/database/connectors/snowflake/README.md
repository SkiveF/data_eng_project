# Catalina - Snowflake connector

## Description

This connector allows to read and write tables on Snowflake efficiently and seamlessly.

## Authentication

To use the connector, you can either :

1. [OPTIMAL] Add the SNOWFLAKE_USERNAME / SNOWFLAKE_PASSWORD environment variables.
2. [NOT ADVISED] Input your username / password as parameters in the creation of the connector.

To add environment variables, follow this [link](https://promotastic.atlassian.net/wiki/spaces/DDIM/pages/2969764114/How-to+passwords+for+the+analytics-toolkit+on+VMss).

*WARNING! The connector only works with Snowflake Service Accounts.*  
*It does not work with Snowflake personal accounts (since Snowflake is linked to SSO). Support for
local authentication will be added soon.*

## Usage examples

````python
import numpy as np
import pandas as pd

from analytics_toolkit.database.connectors import SnowflakeDatabaseConnector

# Choose parameters for your Snowflake account
database = "EXT_FILES_DB"
schema = "ITM"
role = "ANALYST_RTL"
warehouse = "ANALYTICS_RTL_FR"

snowflake = SnowflakeDatabaseConnector(
    role=role, warehouse=warehouse, database=database, schema=schema
)

# Inputs that could be used
table_name = "your_table_name"
new_table_name = "new_table_name"
sql_query = f"SELECT * FROM {table_name} LIMIT 500"

# Get a table from a table name
df_table = snowflake.get_table(table_name)

# Get a table from a SQL Query defining this table
df_query = snowflake.get_table(sql_query)

# Create a new table based on a SQL query
snowflake.create_table(sql_query, new_table_name, if_exists=f"replace")

# Create a new table based on a DataFrame
df = pd.DataFrame(np.ones(shape=(100, 5)), columns=list("abcde"))
snowflake.create_table(df, new_table_name)

# Drop a table
snowflake.drop_table(table_name)

# Check if a table exists
boolean = snowflake.has_table(table_name)

# Get columns of a table
column_list = list(snowflake.get_columns(table_name))

# Get data types of a table
column_dtypes = snowflake.get_columns(table_name)

# Drop columns of a table directly in Snowflake
drop_columns = []
snowflake.drop_columns(table_name, drop_columns)
````

Pros:

* Use many functionalities described in [this tutorial](https://docs.sqlalchemy.org/en/14/orm/tutorial.html) or
  [this one](https://towardsdatascience.com/sqlalchemy-python-tutorial-79a577141a91)

## TO-DO list

Speed up writing on base:

* Modify the insertion method to use
  a [callable](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#insertion-method) (COPY FROM statement?)
* Inspire from the load_data method on snow_utils

Speed up reading on base:

* Use Spark / big data?
* Modify pd.read_sql (tutorial [here](https://towardsdatascience.com/optimizing-pandas-read-sql-for-postgres-f31cd7f707ab))
