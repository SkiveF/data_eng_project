from contextlib import contextmanager
from typing import Optional, Union

import pandas as pd
from analytics_toolkit.sql import is_table_name
from sqlalchemy import create_engine
from sqlalchemy.engine.base import Engine

import snowflake.connector
from snowflake.connector import SnowflakeConnection
from snowflake.connector.pandas_tools import pd_writer
from snowflake.sqlalchemy import URL

from ..generic import DatabaseConnector, SQLAlchemyType


class SnowflakeDatabaseConnector(DatabaseConnector):
    """Connector to use Snowflake in Python"""

    def __init__(
        self,
        role: str,
        warehouse: str,
        database: str,
        schema: str,
        username: str = None,
        password: str = None,
        account: str = None,
    ):
        """
        Instantiates a Snowflake Data Warehouse connector.

        Args:
            role (str): role to use
            warehouse (str): warehouse to use
            database (str): database to use.
            schema (str): schema of the database to use.
            username (str, optional): username in the system. If None, tries to use the environment
                variable "SNOWFLAKE_USERNAME" or prompts the user.
            password (str, optional): password in the system. If None, tries to use the environment
                variable "SNOWFLAKE_PASSWORD" or prompts the user.
            account (str, optional): account to use. If None, takes "catalina.west-europe.azure".
        """
        super().__init__(app_name="snowflake", username=username, password=password)

        # Snowflake specific parameters
        self.database = database
        self.schema = schema
        self.role = role
        self.warehouse = warehouse
        self.account = account if account is not None else "catalina.west-europe.azure"

        # SQLAlchemy engine
        self.engine = self.get_sqlalchemy_engine()
        self.to_sql_method = pd_writer

    def get_sqlalchemy_engine(self) -> Engine:
        database_url = URL(
            account=self.account,
            user=self.username,
            password=self.password,
            warehouse=self.warehouse,
            database=self.database,
            schema=self.schema,
            role=self.role,
        )
        return create_engine(database_url)

    def get_raw_connection(self) -> SnowflakeConnection:
        """Gets the raw Snowflake connection (without SQLAlchemy)"""
        # TODO: try to get it from the SQLAlchemy engine?
        return snowflake.connector.connect(
            account=self.account,
            user=self.username,
            password=self.password,
            warehouse=self.warehouse,
            database=self.database,
            schema=self.schema,
            role=self.role,
        )

    def get_table(self, sql: str) -> pd.DataFrame:
        """
        Fast unloading of DataFrames using the Snowflake connector. We are using
        .fetch_pandas_batches() in order to avoid "KILLED" requests in fetch_pandas_all().
        Batch size will vary based on table size and Snowflake parameters.

        Batches for 10k lines: 2 batches of 2729 / 7271.
        Batches for 100k lines: 4 batches of 2588 / 21216 / 47727 / 28469.

        TODO: compare time between .fetch_pandas_all() and .fetch_pandas_batches()
        TODO: compare to a bare COPY INTO statement? Such as in
        https://copycoding.com/d/unloading-data-from-snowflake-tables

        Args:
            sql (str): SQL select statement, or table name

        Returns:
            pd.DataFrame: data stored in a DataFrame.
        """
        sql = f"SELECT * FROM {sql}" if is_table_name(sql) else sql
        with self.get_raw_connection() as connection:
            cursor = connection.cursor()
            cursor.execute(sql)
            try:
                df_snow = pd.concat(cursor.fetch_pandas_batches(), ignore_index=True)
            except ValueError as err:  # When getting an empty table, iterator is empty
                if str(err) == "No objects to concatenate":
                    df_snow = cursor.fetch_pandas_all()
                else:
                    raise

        df_snow.columns = df_snow.columns.str.lower()

        return df_snow

    def create_table_from_df(
        self,
        df: Union[pd.DataFrame, pd.Series],
        table_name: str,
        if_exists: str = "fail",
        dtype: dict[str, Union[str, SQLAlchemyType]] = None,
        grant_to: Optional[str] = None,
    ):
        """
        Fast loading of table using Snowflake specific methods.

        As of July 12th, 2022, we are forced to change column names to uppercase, and to add a
        timezone to the datetimes. We are not even sure it will work all the time!

        We uppercase columns, otherwise there might be an error in the write_pandas method in the
        snowflake connector. If one column is fully lowercase, it seems SQLAlchemy is able to create
        the table (with uppercase) fails at inserting records. See issue below:
        https://github.com/snowflakedb/snowflake-connector-python/issues/329#issuecomment-674549780

        For datetimes, check the following errors for updates:
        https://github.com/snowflakedb/snowflake-connector-python/issues/600
        https://github.com/snowflakedb/snowflake-connector-python/issues/616

        TODO: compare to a bare COPY INTO statement (as in cloud_utils?)
        TODO: handle better the timezone issues?
        """
        # Format dtype since formatted DF will have uppercase columns
        if dtype is not None:
            dtype = {key.upper(): value for key, value in dtype.items()}

        with self._formatted_data_frame(df) as formatted_df:
            super().create_table_from_df(
                formatted_df,
                table_name,
                if_exists=if_exists,
                dtype=dtype,
                grant_to=grant_to,
            )

    @staticmethod
    @contextmanager
    def _formatted_data_frame(df: pd.DataFrame) -> pd.DataFrame:
        """
        Context manager to format the current DataFrame before sending it to snowflake, and
        un-format it at the end. A context manager is used to avoid big DF copying and to format the
        DataFrame back even if the code failed.

        Args:
            df (pd.DataFrame): DataFrame to format without copying it.

        Returns:
            pd.DataFrame: data with uppercase column & localized datetimes.
        """
        # Storing information for later
        old_columns = df.columns.to_list()
        date_columns = df.select_dtypes(include="datetime").columns

        # Format the DataFrame to make snowflake work (uppercase + timezones)
        for col in date_columns:
            df[col] = df[col].dt.tz_localize("UTC")
        df.columns = df.columns.str.upper()

        try:
            yield df
        finally:
            # Cleanup the modifications done, even if table creation failed.
            df.columns = old_columns  # resetting correct columns
            for col in date_columns:
                df[col] = df[col].dt.tz_localize(None)

    def _drop_columns(
        self, table_name: str, columns: list[str], table_columns: list[str]
    ):
        """Private method to drop columns in a table. To be overridden."""
        drop_columns = set(columns) & set(table_columns)
        query = f"ALTER TABLE {table_name} DROP COLUMN {', '.join(drop_columns)}"
        self.execute_query(query)
