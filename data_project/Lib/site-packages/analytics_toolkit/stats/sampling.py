"""Functions used to sample a population between target and control groups."""
import warnings
from typing import Optional, Union

import pandas as pd
from analytics_toolkit.execution import get_analytics_logger
from analytics_toolkit.stats.stats_tests import t_test
from sklearn.model_selection import train_test_split


def split_target_control(
    df_to_split: pd.DataFrame,
    control_size: Union[float, int] = 0.1,
    stratify_vars: Union[str, list[str], None] = None,
    control_vars: Union[str, list[str], None] = None,
    threshold: float = 0.05,
    n_iterations: int = 30,
    include_test_results: bool = False,
    add_selected_col_as: Union[str, None] = None,
    random_state: Optional[int] = None,
) -> tuple[pd.DataFrame, ...]:
    """
    Splits a DataFrame to create 2 dataframes: targeted & control.

    Args:
        df_to_split (pd.DataFrame): Dataframe to split.
        control_size (Union[float, int], optional): Size of control group. Defaults to 0.1.
            If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to
                include in the test split.
            If int, represents the absolute number of test samples.
        stratify_vars (Union[str, list[str], None], optional): columns to use for stratification.
            If None, no stratification is done. Defaults to None.
        control_vars (Union[str, list[str], None], optional): columns to perform statistical tests
            on (with the statistical thresholds defined). The tests are a ks test (numerical
            columns) and a chi2 test (categorical columns). If they do not pass, rerun the sampling.
            ks test: compare for each variables whether the distribution of 2 samples (control and
                target) are identical.
            chi2 test: test whether there is an effect of the split on each variables.
            If None, no controls are done. Defaults to None.
        threshold (float, optional): p-value threshold to use to quantify the statistical
            significance of a result under a null hypothesis. Defaults to 0.05.
        n_iterations (int, optional): In case of controls, number of iterations to do to take the
            most representative split. Defaults to 30.
        include_test_results (bool, optional): If True, include the test results DataFrame as a
            third element in the returned tuple. Defaults to False.
        add_selected_col_as (Union[str, None], optional): if not None, includes a new column named
            with the given name, with 1s (targeted group) - 0s (control group) in the original
            DataFrame. Defaults to None.
        random_state (Optional[int], optional): controls the shuffling applied to the data before
            applying the split. Pass an int for reproducible output across multiple function calls.
            If None, no seed is passed. Defaults to None.

    Returns: two or three DataFrames
        df_target (pd.DataFrame): target population
        df_control (pd.DataFrame): control population
        df_test_results (pd.DataFrame): if control_vars is not None & include_test_results is True
    """
    target_control_splitter = TargetControlSplitter(
        df_to_split,
        control_size=control_size,
        stratify_vars=stratify_vars,
        control_vars=control_vars,
        threshold=threshold,
        n_iterations=n_iterations,
        include_test_results=include_test_results,
        add_selected_col_as=add_selected_col_as,
        random_state=random_state,
    )

    return target_control_splitter.split_target_control()


class TargetControlSplitter:
    """Class to split a DataFrame between target and control."""

    def __init__(
        self,
        df_to_split: pd.DataFrame,
        control_size: Union[float, int] = 0.1,
        stratify_vars: Union[str, list[str], None] = None,
        control_vars: Union[str, list[str], None] = None,
        threshold: float = 0.05,
        n_iterations: int = 30,
        include_test_results: bool = False,
        add_selected_col_as: Union[str, None] = None,
        random_state: Optional[int] = None,
    ) -> None:
        """Class initialization. See public method for more information."""
        # Input parameters
        self.df_to_split = df_to_split
        self.control_size = control_size
        self.stratify_vars = (
            [stratify_vars] if isinstance(stratify_vars, str) else stratify_vars
        )
        self.control_vars = (
            [control_vars] if isinstance(control_vars, str) else control_vars
        )
        self.add_selected_col_as = add_selected_col_as
        self.include_test_results = include_test_results
        self.threshold = threshold
        self.n_iterations = n_iterations
        self.random_state = random_state

        # Output parameters - splitted DF and test results DataFrame
        self.df_target = pd.DataFrame()
        self.df_control = pd.DataFrame()
        self.df_tests_results = pd.DataFrame()

        self.logger = get_analytics_logger()

    def split_target_control(self) -> tuple[pd.DataFrame, ...]:
        """Main method of the class: splits the DataFrame into target & control groups."""
        if self.control_vars is None:
            self.df_target, self.df_control = self.split_df(self.df_to_split)
        elif self.control_vars is not None and self.stratify_vars is None:
            splits = (self.split_df(self.df_to_split) for _ in range(self.n_iterations))
            dfs = min(splits, key=self.get_mean_gap_average)
            self.df_target, self.df_control, self.df_tests_results = dfs
        else:
            # If we stratify, let's cut our DF so that we take the best split for each stratified
            # group. We do not keep the best split in general (as done above) as it might be good
            # for a group but bad for another
            dfs_target, dfs_control, dfs_tests_results = [], [], []
            for _, df_to_split in self.df_to_split.groupby(self.stratify_vars):
                splits = (self.split_df(df_to_split) for _ in range(self.n_iterations))
                dfs = min(splits, key=self.get_mean_gap_average)
                dfs_target.append(dfs[0])
                dfs_control.append(dfs[1])
                dfs_tests_results.append(dfs[2])

            self.df_target = pd.concat(dfs_target)
            self.df_control = pd.concat(dfs_control)
            self.df_tests_results = pd.concat(dfs_tests_results)

        # If during control, some p-values are below threshold, raise a warning.
        if self.control_vars is not None and not (
            self.df_tests_results.loc["p_value"] >= self.threshold
        ).all(axis=None):
            columns = self.get_failing_test_columns()
            message = f"""
            Warning! There's a variable with a p-value below the threshold, for groups:
            {', '.join(columns)}. Try to lower the threshold, or increase the number of
            iterations. Check df_tests_results for more information.
            """
            message = message.replace("\n", "").replace("\t", "")
            self.logger.warning(message)
            warnings.warn(message, UserWarning)

        # Include selected column in DataFrame if needed.
        if self.add_selected_col_as is not None:
            self.df_to_split[self.add_selected_col_as] = False
            self.df_to_split.loc[self.df_target.index, self.add_selected_col_as] = True

        # Return either two or three DataFrames
        if self.control_vars is not None and self.include_test_results:
            return self.df_target, self.df_control, self.df_tests_results
        else:
            return self.df_target, self.df_control

    def split_df(self, df_to_split: pd.DataFrame) -> tuple[pd.DataFrame, ...]:
        """Splits a DataFrame in two, and tests the representativeness of the split if needded."""
        stratify = df_to_split[self.stratify_vars] if self.stratify_vars else None
        df_target, df_control = train_test_split(
            df_to_split,
            test_size=self.control_size,
            stratify=stratify,
            random_state=self.random_state,
        )
        if self.control_vars is None:
            return df_target, df_control
        else:
            df_test_results = self.compute_split_similarity(df_target, df_control)
            return df_target, df_control, df_test_results

    def compute_split_similarity(
        self, df_target: pd.DataFrame, df_control: pd.DataFrame
    ) -> pd.DataFrame:
        """
        Compute the similarity of a split in a DataFrame. To do so, for all numerical control
        variables, test whether the means are close enough. Returns DF containing the tests results.
        """
        num_vars = df_target[self.control_vars].select_dtypes("number").columns
        df_tests_results = t_test(
            df_target,
            df_control,
            columns=num_vars,
            segment_by=self.stratify_vars,
            threshold=self.threshold,
            include_global_results=False,
            assume_equal_var=True,
        )

        return df_tests_results

    def get_mean_gap_average(self, dfs: tuple[pd.DataFrame, ...]) -> float:
        """Gets the mean difference for a split, averaged on all control columns."""
        df_tests_results = dfs[2]
        mean_gap_average = df_tests_results.loc["mean_gap"].mean()
        if self.stratify_vars is not None:  # Also average on all splits if needed
            mean_gap_average = mean_gap_average.mean()

        return mean_gap_average

    def get_failing_test_columns(self) -> list[str]:
        """Computes the columns on which the tests are failing."""
        if self.stratify_vars is None:
            failing = self.df_tests_results.loc["p_value"] <= self.threshold
            columns = failing.loc[failing].index
        else:
            failing = (self.df_tests_results.loc["p_value"] <= self.threshold).stack()
            format_cols = lambda x: "/".join(str(element) for element in x)
            columns = failing.loc[failing].index.map(format_cols).str.strip(", ")

        return columns
