"""Functions to process statistical test."""
import abc
import warnings
from typing import Optional, Union

import pandas as pd
from scipy.stats import chi2_contingency, ks_2samp
from statsmodels.stats.weightstats import ttest_ind


def t_test(
    df_target: pd.DataFrame,
    df_control: pd.DataFrame,
    columns: Union[str, list[str]],
    segment_by: Union[str, list[str], None] = None,
    threshold: float = 0.05,
    include_global_results: bool = True,
    assume_equal_var: bool = True,
    weights_col: Optional[str] = None,
) -> pd.DataFrame:
    """
    Calculate the t-test for the means of two independent population (target and control).
    Objective of this function is to check whether two populations have the same means on specific
    columns.

    Args:
        df_target (pd.DataFrame): target population
        df_control (pd.DataFrame): control population
        columns (Union[str, list[str]]): names of the columns to use for the test evaluation. This
            function assumes the columns exists in both control and target DFs.
        segment_by (Union[str, list[str], None], optional): names of the columns we want to segment
            by. If specified, groups by the given columns and also do the test by segment (only for
            values that are in both target & control groups). If None, does not run tests by
            segment. Defaults to None.
        threshold (float, optional): threshold to use to quantify the statistical significance of a
            result under a null hypothesis. Defaults to 0.05.
        include_global_results (bool, optional): if False, does not include global results when
            doing a stratified test (using by_segment argument). Defaults to True.
        assume_equal_var (bool): True or False
            If True, then the standard deviation of the samples is assumed to be the same.
            If False, then Welch t-test with Satterthwait degrees of freedom is used.
            Defaults to True.
        weights_col (str, optional):
            Column containing the weights for the t-test. They will give more importance to certain
            rows in the table. This function assumes columns exists in both control and target DFs.

    Returns:
        pd.DataFrame: with columns "t_statistic", "p_value", "degrees_of_freedom", "mean_gap", & "obs_p_value"
    """
    statistical_test = TTest(
        df_target,
        df_control,
        columns,
        segment_by=segment_by,
        threshold=threshold,
        include_global_results=include_global_results,
        assume_equal_var=assume_equal_var,
        weights_col=weights_col,
    )
    return statistical_test.run_test()


def ks_test(
    df_target: pd.DataFrame,
    df_control: pd.DataFrame,
    columns: Union[str, list[str]],
    segment_by: Union[str, list[str], None] = None,
    threshold: float = 0.05,
    include_global_results: bool = True,
    mode: str = "auto",
) -> pd.DataFrame:
    """
    Calculate the KS-test to compare the distribution of 2 samples (control and target).
    The null hypothesis is that the two distributions are identical.
    This test is perform on each numeric (continuous) variables mentioned in columns.

    Args:
        df_target (pd.DataFrame): target population
        df_control (pd.DataFrame): control population
        columns (Union[str, list[str]]): columns to use for the test evaluation. This function
            assumes the columns exists in both control and target DFs.
        segment_by (Union[str, list[str], None], optional): If specified, groups by the given
            columns and also do the test by segment (only for values that are in both target &
            control groups). If None, does not run tests by segment. Defaults to None.
        threshold (float, optional): threshold to use to quantify the statistical significance of a
            result under a null hypothesis. Defaults to 0.05.
        include_global_results (bool, optional): if False, does not include global results when
            doing a stratified test (using by_segment argument). Defaults to True.
        mode (str, optional): Defines the method used for computing the p-value.
            The following options are available:
                'auto': use 'exact' for small size arrays, 'asymp' for large
                'exact': use exact distribution of test statistic
                'asymp': use asymptotic distribution of test statistic
            If the mode is 'auto', the computation is exact if the sample sizes are less than 10000.
            For larger sizes, the computation uses the Kolmogorov-Smirnov distributions to compute
            an approximate value.
            Defaults to "auto".

    Returns:
        pd.DataFrame: table with "t_statistic", "p_value", "degrees_of_freedom" & "obs_p_value"
    """
    statistical_test = KSTest(
        df_target,
        df_control,
        columns,
        segment_by=segment_by,
        threshold=threshold,
        mode=mode,
        include_global_results=include_global_results,
    )
    return statistical_test.run_test()


def chi2_test(
    df_target: pd.DataFrame,
    df_control: pd.DataFrame,
    columns: Union[str, list[str]],
    segment_by: Union[str, list[str], None] = None,
    threshold: float = 0.05,
    include_global_results: bool = True,
) -> pd.DataFrame:
    """
    This function computes the chi-square statistic and p-value for the hypothesis test of
    independence of the observed frequencies in the contingency table made from each categorical
    variables passed in columns to test.

    Args:
        df_target (pd.DataFrame): target population
        df_control (pd.DataFrame): control population
        columns (Union[str, list[str]]): columns to use for the test evaluation. This function
            assumes the columns exists in both control and target DFs.
        segment_by (Union[str, list[str], None], optional): If specified, groups by the given
            columns and also do the test by segment (only for values that are in both target &
            control groups). If None, does not run tests by segment. Defaults to None.
        threshold (float, optional): threshold to use to quantify the statistical significance of a
            result under a null hypothesis. Defaults to 0.05.
        include_global_results (bool, optional): if False, does not include global results when
            doing a stratified test (using by_segment argument). Defaults to True.

    Returns:
        pd.DataFrame: Results dataframe with "t_statistic", "p_value",
            "degrees_of_freedom","expected_freq" & "obs_p_value",

    """
    statistical_test = Chi2Test(
        df_target,
        df_control,
        columns,
        segment_by=segment_by,
        threshold=threshold,
        include_global_results=include_global_results,
    )
    return statistical_test.run_test()


class StatisticalTest(metaclass=abc.ABCMeta):
    """Class to perform statistical tests on specific variables"""

    def __init__(
        self,
        df_target: pd.DataFrame,
        df_control: pd.DataFrame,
        columns: Union[str, list[str]],
        segment_by: Union[str, list[str], None] = None,
        threshold: float = 0.05,
        include_global_results: bool = True,
        name: str = "statistical_test",
        rejection_message: str = "[REJECTED] Hypothesis may be rejected.",
        acceptance_message: str = "[ACCEPTED] Hypothesis may not be rejected.",
    ) -> None:
        """Class initialization. See public methods for information on variables."""
        # Input DataFrame: global DF with all information
        dfs = [df_target.assign(selected=True), df_control.assign(selected=False)]
        self.df_total = pd.concat(dfs, ignore_index=True)

        # Input parameters
        self.columns = [columns] if isinstance(columns, str) else columns
        self.segment_by = [segment_by] if isinstance(segment_by, str) else segment_by
        self.threshold = threshold
        self.include_global_results = include_global_results

        # Some parameters specific to each child
        self.name = name
        self.messages = {True: rejection_message, False: acceptance_message}

    def run_test(self) -> pd.DataFrame:
        """Executes the statistical test"""
        if self.segment_by is None:
            df_results = self._run_test(self.df_total)
        else:
            df_results = self.df_total.groupby(self.segment_by).apply(self._run_test)
            reorder_index = [self.name] + self.segment_by
            df_results = df_results.reorder_levels(reorder_index)

            if self.include_global_results:
                df_total = self._run_test(self.df_total)
                df_total.reset_index(inplace=True)
                df_total[self.segment_by] = "all"
                df_total.set_index(reorder_index, inplace=True)
                df_results = pd.concat([df_total, df_results])

        return df_results

    @abc.abstractmethod
    def _run_test(self, df: pd.DataFrame) -> pd.DataFrame:
        """Specific test execution for each child class."""

    def remove_numeric_columns(self):
        """Check if there are numeric columns. If so, removes them and raises a warning."""
        # Filter out non-numeric columns
        numeric_columns = self.df_total[self.columns].select_dtypes("number").columns
        non_numeric_columns = set(self.columns) - set(numeric_columns)
        self.columns = set(self.columns) & set(non_numeric_columns)

        # Warn if a non-numeric column is passed
        if len(numeric_columns) > 0:
            msg = f"Only non-numeric columns are tested in {self.name}.\n Ignoring columns: {', '.join(numeric_columns)}"
            warnings.warn(msg, UserWarning)

    def remove_non_numeric_columns(self):
        """Check if there are non-numeric columns. If so, removes them and raises a warning."""
        # Filter out non-numeric columns
        numeric_columns = self.df_total[self.columns].select_dtypes("number").columns
        non_numeric_columns = set(self.columns) - set(numeric_columns)
        self.columns = set(self.columns) & set(numeric_columns)

        # Warn if a non-numeric column is passed
        if len(non_numeric_columns) > 0:
            msg = f"Only numeric columns are tested in {self.name}.\n Ignoring columns: {', '.join(non_numeric_columns)}"
            warnings.warn(msg, UserWarning)


class TTest(StatisticalTest):
    """Class to execute t-tests"""

    def __init__(
        self,
        df_target: pd.DataFrame,
        df_control: pd.DataFrame,
        columns: Union[str, list[str]],
        segment_by: Union[str, list[str], None] = None,
        threshold: float = 0.05,
        include_global_results: bool = True,
        assume_equal_var: bool = True,
        weights_col: str = None,
    ) -> None:
        """Class initialization. See public methods for information on variables."""
        super().__init__(
            df_target,
            df_control,
            columns,
            segment_by=segment_by,
            threshold=threshold,
            include_global_results=include_global_results,
            name="t_test",
            rejection_message="[NOT EQUAL] - Null hypothesis of equal population means may be rejected",
            acceptance_message="[EQUAL] - Null hypothesis of equal population means may not be rejected",
        )

        self.remove_non_numeric_columns()

        # T-test specific parameters
        self.assume_equal_var = assume_equal_var
        self.weights_col = weights_col

    def _run_test(self, df: pd.DataFrame) -> pd.DataFrame:
        """Runs an t-test"""
        # Create the results DataFrame
        idx_cols = ["t_statistic", "p_value", "degrees_of_freedom"]
        index = idx_cols + ["obs_p_value"]
        df_results = pd.DataFrame(index=index, columns=self.columns)
        df_results.index.name = self.name

        # Get the control / target table ready
        df_target, df_control = df[df["selected"]], df[~df["selected"]]

        # Compute the optional test parameters
        usevar = "pooled" if self.assume_equal_var else "unequal"
        weights = (None, None)
        if self.weights_col is not None:
            weights = (df_target[self.weights_col], df_control[self.weights_col])

        # Evaluate t_statistics and p_value for each column
        for column in self.columns:
            t_statistic, p_value, degrees_of_freedom = ttest_ind(
                df_target[column], df_control[column], usevar=usevar, weights=weights
            )
            df_results.loc[idx_cols, column] = t_statistic, p_value, degrees_of_freedom
            mean_gap = df_target[column].mean() / df_control[column].mean()
            df_results.loc["mean_gap", column] = abs(mean_gap - 1)
            threshold = self.threshold
            df_results.loc["obs_p_value", column] = self.messages[p_value <= threshold]

        return df_results


class KSTest(StatisticalTest):
    """Class to execute KS-tests"""

    def __init__(
        self,
        df_target: pd.DataFrame,
        df_control: pd.DataFrame,
        columns: Union[str, list[str]],
        segment_by: Union[str, list[str], None] = None,
        threshold: float = 0.05,
        include_global_results: bool = True,
        mode: str = "auto",
    ) -> None:
        """Class initialization. See public methods for information on variables."""
        super().__init__(
            df_target,
            df_control,
            columns,
            segment_by=segment_by,
            threshold=threshold,
            include_global_results=include_global_results,
            name="ks_test",
            rejection_message="[NOT IDENTICAL] - Null hypothesis of identical distribution may be rejected",
            acceptance_message="[IDENTICAL] - Null hypothesis of identical distribution may not be rejected",
        )

        self.remove_non_numeric_columns()

        # KS-test specific parameters
        self.mode = mode

    def _run_test(self, df: pd.DataFrame) -> pd.DataFrame:
        """Runs an ks-test"""
        # Create the results DataFrame
        idx_cols = ["t_statistic", "p_value"]
        index = idx_cols + ["obs_p_value"]
        df_results = pd.DataFrame(index=index, columns=self.columns)
        df_results.index.name = self.name

        # Evaluate t_statistics and p_value for each column
        for column in self.columns:
            t_statistic, p_value = ks_2samp(
                df.loc[df["selected"], column].values,
                df.loc[~df["selected"], column].values,
                mode=self.mode,
            )
            df_results.loc[idx_cols, column] = t_statistic, p_value
            threshold = self.threshold
            df_results.loc["obs_p_value", column] = self.messages[p_value <= threshold]

        return df_results


class Chi2Test(StatisticalTest):
    """Class to execute Chi2 tests"""

    def __init__(
        self,
        df_target: pd.DataFrame,
        df_control: pd.DataFrame,
        columns: Union[str, list[str]],
        segment_by: Union[str, list[str], None] = None,
        threshold: float = 0.05,
        include_global_results: bool = True,
    ) -> None:
        """Class initialization. See public methods for information on variables."""
        super().__init__(
            df_target,
            df_control,
            columns,
            segment_by=segment_by,
            threshold=threshold,
            include_global_results=include_global_results,
            name="chi2_test",
            rejection_message="[NOT INDEPENDENT] - Null hypothesis of independence may be rejected",
            acceptance_message="[INDEPENDENT] - Null hypothesis of independence may not be rejected",
        )

        self.remove_numeric_columns()

    def _run_test(self, df: pd.DataFrame) -> pd.DataFrame:
        """Runs an chi2-test"""
        # Create the results DataFrame
        idx_cols = ["t_statistic", "p_value", "degrees_of_freedom", "expected_freq"]
        index = idx_cols + ["obs_p_value"]
        df_results = pd.DataFrame(index=index, columns=self.columns)
        df_results.index.name = self.name

        # Evaluate t_statistics and p_value for each column
        for column in self.columns:
            contingency_table = pd.crosstab(df[column], df["selected"], margins=True)
            chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)
            df_results.loc[idx_cols, column] = chi2_stat, p_value, dof, expected
            threshold = self.threshold
            df_results.loc["obs_p_value", column] = self.messages[p_value <= threshold]

        return df_results
